# 爬虫
## 概述
三个部分：
* 主爬虫 
* 代理ip池
* 原始数据池

## 代理ip池（ip队列）
由于需要采集的网站会对ip采取限制措施，尚不清楚具体的规则，建议使用高匿代理ip。

为了方便管理，将代理ip池放在了redis上。代理ip池即是一个代理ip的 url 队列。

为了维护这个代理池，我也写了一个python脚本去网站上抓取 ip:port，由于该网站需要登录，所以需要先登陆，获得Cookie，然后在python脚本里面设置 header 的 cookie 项。



## 原始数据池（数据队列）
数据抓取需要用数据库里面的值作为输入，取得返回的数据。需要采集的数据量比较大，不宜全部缓存到本地内存中，可以使用 cursor 来逐次获取数据。

从数据库取到的数据存放在一个队列中，供爬虫提取，同时，当爬虫触发了异常（一般由于代理ip不可用），爬虫正在使用的数据将被放回队列，以供后续重试。

## 主爬虫
可以先用 chrome 的调试工具分析一下到达目的页面的 http 请求过程，以及 http 请求头（大多数无法访问到目标页面是由于header的问题）。
爬虫的过程是：
1. 获取目标页面 html 或 json 数据（可能需要提交数据）
2. 分析所需数据的上下文
3. 用正则表达式或者相关工具提取感兴趣的数据
4. 将数据写入数据库

抓取过程中需考虑网络异常等情况，并对发生异常的数据进行重试。

该爬虫从 redis 获取队首代理 ip（阻塞式） ，访问成功重新入队，如果失败则丢弃这个ip，并启动异常处理（即将输入数据重新放回数据队列）。

为了提高性能，使用了多线程。
